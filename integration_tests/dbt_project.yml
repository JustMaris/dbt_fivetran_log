name: 'fivetran_log_integration_tests'
version: '1.1.0'

config-version: 2
profile: 'integration_tests'

dispatch:
  - macro_namespace: dbt_utils
    search_order: ['spark_utils', 'dbt_utils']

vars:
  fivetran_log:
    fivetran_platform_schema: fivetran_platform_integration_tests
    fivetran_platform_account_identifier: "account"
    fivetran_platform_incremental_mar_identifier: "incremental_mar"
    fivetran_platform_connector_identifier: "connector"
    fivetran_platform_credits_used_identifier: "credits_used"
    fivetran_platform_usage_cost_identifier: "usage_cost"
    fivetran_platform_destination_identifier: "destination"
    fivetran_platform_destination_membership_identifier: "destination_membership"
    fivetran_platform_log_identifier: "log"
    fivetran_platform_transformation_identifier: "transformation"
    trigger_table: "{{ fivetran_utils.snowflake_seed_data('trigger_table') }}"
    fivetran_platform_user_identifier: "user"


models:
  fivetran_log:
    +schema: fivetran_platform

seeds:
  fivetran_log_integration_tests:
    +column_types:
      _fivetran_synced: timestamp
    account:
      +column_types:
        created_at: timestamp
    incremental_mar:
      +column_types:
        measured_date: timestamp
        incremental_rows: "{{ 'int64' if target.type == 'bigquery' else 'bigint' }}"
    connector:
      +column_types:
        signed_up: timestamp
    credits_used:
      +column_types:
        credits_consumed: "{{ 'int64' if target.type == 'bigquery' else 'bigint' }}"
    destination:
      +column_types:
        created_at: timestamp
        id: "{{ 'string' if target.type in ('bigquery', 'spark', 'databricks') else 'varchar' }}"
    destination_membership:
      +column_types:
        activated_at: timestamp
        joined_at: timestamp
    log:
      +column_types:
        time_stamp: timestamp
        transformation_id:  "{{ 'string' if target.type in ('bigquery', 'spark', 'databricks') else 'varchar' }}"
    transformation:
      +column_types:
        created_at: timestamp
        destination_id: "{{ 'string' if target.type in ('bigquery', 'spark', 'databricks') else 'varchar' }}"
        id:  "{{ 'string' if target.type in ('bigquery', 'spark', 'databricks') else 'varchar' }}"
    trigger_table:
      +quote_columns: "{{ true if target.type in ('redshift', 'postgres') else false }}"
      +enabled: "{{ true if target.type != 'snowflake' else false }}"
      +column_types:
        transformation_id:  "{{ 'string' if target.type in ('bigquery', 'spark', 'databricks') else 'varchar' }}"
    trigger_table_snowflake:
      +enabled: "{{ true if target.type == 'snowflake' else false }}"
    user:
      +column_types:
        created_at: timestamp

clean-targets:         # directories to be removed by `dbt clean`
  - "target"
  - "dbt_packages"
  - "dbt_modules"